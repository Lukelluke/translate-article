- <https://gto76.github.io/linux-cheatsheet/>   LINUX自查代码、

- 

- 语音识别降噪

  - **SNR**：信噪比，正常声音信号与无信号时噪声信号([功率](https://baike.baidu.com/item/%E5%8A%9F%E7%8E%87))的差值。用dB表示。如80dB，即输出信号功率是噪音功率的 $10^8$ 倍。
  - 对比降噪和没有降噪的识别文本对比和频谱分析
    - [ ] DNN本身就有很强的抗噪性，在弱噪声和纯净语音下，基本都不是问题，通常场景下，这点噪声，用线上数据或者刻意的加噪训练，是完全可以吸收掉的，只有在20db以下，含噪样本的频谱特征和纯净样本的频谱特征差异太大，用模型学习收敛就不太好，需要降噪前端
    - [ ] **降噪对于纯净语音或者弱噪声环境下，不可避免的对语音有所损伤，只有在恶劣的环境下，会起到非常明显的作用**。传统降噪是基于统计意义上面的一个处理，难以做到瞬时噪声的精准估计，这个本身就是一个近似的，粗略模糊化的一个处理，即不可避免的对噪声欠估计或者过估计，本身难把握，保真语音，只去噪，如果噪声水平很弱，这个降噪也没有什么用或者说没有明显作用，去噪力度大了，又会破坏语音。对于测试样本集，如果90%的样本都是在20db上，只有200来条的环境比较恶劣。所以通常起来反作用。
    - [ ] 降噪里面的很多平滑处理，是有利于改善听感的，但是频谱也变得模糊，这些特征是否能落到正确的类别空间里面，也是存在疑问的。可以通过在前端降噪基础上，再过一遍声学模型重新训练，但是比较耗时间
    - [ ] 传统降噪，通常噪声初始化会利用初始的前几帧，而如果开头是语音，那就会失真很明显
    - [ ] 估计出噪声水平，在SNR(信噪比)低的情况下降噪，SNR(信噪比)高时，不处理或者弱处理，在中间水平，进行软处理，这个思路可以考虑
    - [ ] 线上数据，影响识别因素排序是 口语化、方言、短词，其次才是噪声，另外，少量混响，语速，音量，也是影响因素之一。

- 音频信号具有明显的协同发音现象，因此必须考虑长时相关性。由于循环神经网络RNN具有更强的长时建模能力，使得 RNN 也逐渐替代 DNN 和 CNN 成为语音识别主流的建模方案。

- 音色：即音质，是一种声音区别另一种声音的基本特性；(你声音好不好听)

  音调：声音的高低，取决于声波的频率；（你声音尖不尖）

  音强：声音的强弱，由声波的振动幅度决定；（响不响？）

  音长：取决于发音时间的长短。

- NLP中的RNN深度学习方法[地址](<https://mp.weixin.qq.com/s?__biz=MzI4ODY2NjYzMQ==&mid=2247484759&idx=1&sn=03b92284da314d26a86d3a27976c6e6a&chksm=ec3ba03fdb4c29295e00456fd7db7b62f3adbcd94611ae2f3f64bd1679b41a2ebfa044204af5&scene=21#wechat_redirect>)

  - 词嵌入，词向量，word2vec
  - [ ] 