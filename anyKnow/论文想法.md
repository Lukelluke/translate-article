目前研究点：fastspeech

1. 很多人试图使用深度学习从原始音频中提取特征去代替mfcc**

   2016年Google尝试从原始音频中学习特征，其中为了尽可能保留原始音频的信息，模型输入为复数信号的时频谱，其架构为：

   ![img](https://pic2.zhimg.com/80/v2-2de7013395665a165c2ada552201cf35_hd.jpg)

   其中最下方的输入$x1(t)$, $x2(t)$ 分别表示音频信号经过傅里叶变换之后的**(实部)**和**虚部**，虚线框部分的模型负责完成信号处理，并将复数信号转换成实数信号，虚线框上面的部分则负责和将实数信号转换成更加抽象的特征并完成数据分类;

2. WORLD声码器可与谷歌的开源语音合成模型Tacotron结合使用。

   Tacotron是一种端到端的TTS深度学习模型，所谓 “端到端” 是指利用前端文本直接预测后端声谱，整合了之前的独立子模块，达到系统整体最优；WORLD是一种声码器，与Tacotron结合可基于人类发音频谱将文字转化为与人类发音相似的声音：将每个文字转化为拼音之后，声码器会把每个拼音看作为一个序列而Tacotron会在此基础上预测每段需要合成语音的序列，随后WORLD声码器再将预测出的声谱转换为原始的声音波形。Tacotron主要负责确定此声谱特征能否使用WORLD将其恢复为声音波形并评估语音质量是否符合要求。

   <https://blog.csdn.net/vn9PLgZvnPs1522s82g/article/details/86697936>

3. [谷歌AI翻译娘的异常进化：拿到音频，不做语音识别，也不翻成文本](https://zhuanlan.zhihu.com/p/62671765)

4. [速度提升270倍！微软和浙大联合推出全新语音合成系统FastSpeech - 微软亚洲研究院的文章 - 知乎](https://zhuanlan.zhihu.com/p/67544816)

5. [CTC和Encoder-Decoder有什么关系? - 王赟 Maigo的回答 - 知乎](https://www.zhihu.com/question/279927514/answer/410472982)

6. 